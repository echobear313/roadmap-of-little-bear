分为三个网络，大小分别是
* propoasl-net: 12
* refine-net: 24
* output-net:48
propoasl-net和refine-net用来把脸粗筛、细筛选出来、抠出来，output-net筛选脸的同时做关键点的回归。   
12，24输出之后生成hard example和原来的数据集一起作为下一个网络的输入，具体思路如下:
12-net(生成12大小的数据集) ---> 24-net(12-net生成的hard example+生成的24大小的数据集) ---> 48-net   
这个是不是online hard example mining，它是在训练的时候同时做的。

* 生成数据

生成数据的时候，有一个ground truth, 高或宽小于40的话，我就认为那不是一只手，是错的标签。在12-net, 24-net输出时使用NMS（非极大值抑制）去除重复框，可以既减少计算量。  

* 标签

对两个数据集，前两个网络用到的数据集没有关键点信息，负样本没有关键点信息，没有bounding box信息，就都标为-1，在计算loss的时候只对非-1进行反向传播。因为是计算偏移量，这个值一定是`(-1, 1)`的，也就是bounding box的偏移量除以图片大小。所以有效的标签肯定不会有-1这个值。  

所有在整理数据中，对于每个图片进行了15个label的标注信息：    

1. 第1列：为正负样本标志，１正样本, 0负样本,-1部分样本,3关键点信息

2. 第2-5列：为边框偏移，为float类型，对于无边框信息的数据，全部置为-1

3. 42列：为关键点偏移，为float类型，对于无边框信息的数据，全部置为-1    

上面是训练的时候的标签，下面就是忽略-1:    

> 修改softmax_loss_layer.cpp　增加判断，只对于1,0计算loss值
修改euclidean_loss_layer.cpp　增加判断，对于置为-1的不进行loss计算

换句话说，hdf5文件里有四块区域，除了data，还有label(标注正负部分样本), points(21个关键点,所以有42列), roi(边框信息，两个点，四列) 。